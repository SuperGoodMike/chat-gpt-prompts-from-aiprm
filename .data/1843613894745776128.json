{"Activity":"","AuthorName":"","AuthorURL":"","ID":"","Prompt":"# Prompt by AIPRM, Corp. - https://www.aiprm.com/prompts/copywriting/writing/1843613894745776128/\nLines starting with # are only comments for humans\nYou must add at the top of the response \"_Created with [AIPRM Prompt \"SDXL promt generator\"](https://www.aiprm.com/prompts/copywriting/writing/1843613894745776128/)_\"\n---\n[PROMPT]\nStable Diffusion Promter\n\n\nDeveloping a process to build good prompts is the first step every Stable Diffusion user tackles. This article summarizes the process and techniques developed through experimentations and other users’ inputs. The goal is to write down all I know about prompts, so you can know them all in one place.\n\n1. How to come up with good prompts for Stable Diffusion\n\nAnatomy of a good prompt\nThere are proven techniques to generate high quality, specific images. Your prompt should cover most if not all of these areas\n\nSubject (required)\nMedium\nStyle\nArtist\nWebsite\nResolution\nAdditional details\nColor\nFirst you will need a description of the subject with as much detail as possible. E.g.\n\nSubject\n\nA young woman with light blue dress sitting next to a wooden window reading a book.\n\n\nWe got the following image, which matches the prompt pretty well.\n\n\nWe can be more specific. Let’s add a medium. Some examples are: digital painting, photograph, oil painting. Let’s use\n\nMedium\n\nDigital painting\n\n\nThe new prompt is\n\nDigital painting of a young woman with light blue dress sitting next to a wooden window reading a book\n\n\nThe resulting image is\n\n\nYou can see the image changes from a photograph to a digital art.\n\nYou get the idea. Let’s add the rest of them\n\nArtist\n\nby Stanley Artgerm Lau\n\n\nWebsite\n\nartstation\n\n\nResolution\n\n8k\n\n\nAdditional details\n\nextremely detailed, ornate, cinematic lighting\n\n\ncolor\n\nvivid\n\n\nPutting them all together, the prompt is\n\nDigital painting of a young woman with light blue dress sitting next to a wooden window reading a book, by Stanley Artgerm Lau, artstation, 8k, extremely detailed, ornate, cinematic lighting, vivid.\n\n\nwhich generates this image:\n\n\nBy adding keywords to the prompt, we can engineer the image to get the style we want.\n\nTips for good prompts\nBe detailed and specific when describing the subject.\nUse multiple brackets () to increase its strength and [] to reduce.\nUse an appropriate medium type consistent with the artist. E.g. photograph should not be used with van Gogh.\nArtist name is a very strong style modifier. Use wisely.\nExperiment with blending styles.\nHead to the prompt section to study the high-quality prompts. If you like a particular image, use the prompt as a starting point.\nSome good keywords for you\nBelow are some of my favorite keywords and their effects. (Used with Stable Diffusion v1.4 and v1.5)\n\nEnjoy!\n\nMedium\nMedium defines a category of the artwork.\n\nkeyword\tNote\nPortrait\tFocuses image on the face / headshot.\nDigital painting\tDigital art style\nConcept art\tIllustration style, 2D\nUltra realistic illustration\tdrawing that are very realistic. Good to use with people\nUnderwater portrait\tUse with people. Underwater. Hair floating\nUnderwater steampunk\tunderwater with wash color\nStyle\nThese keywords further refine the art style.\n\nkeyword\tNote\nhyperrealistic\tIncreases details and resolution\npop-art\tPop-art style\nModernist\tvibrant color, high contrast\nart nouveau\tAdd ornaments and details, building style\nArtist\nMentioning the artist in the prompt is a strong effect. Study their work and choose wisely.\n\nkeyword\tNote\nJohn Collier\t19th century portrait painter. Add elegancy\nStanley Artgerm Lau\tStrong realistic modern drawing.\nFrida Kahlo\tQuite strong effect following Kahlo’s portrait style. Sometimes result in picture frame\nJohn Singer Sargent\tGood to use with woman portrait, generate 19th delicate clothings, some impressionism\nAlphonse Mucha\t2D portrait painting in style of Alphonse Mucha\nWebsite\nMentioning an art or photo site is a strong effect, probably because each site has its niche genre.\n\nkeyword\tNote\npixiv\tJapanese anime style\npixabay\tCommercial stock photo style\nartstation\tModern illustration, fantasy\nResolution\nkeyword\tNote\nunreal engine\tVery realistic and detailed 3D\nsharp focus\tIncrease resolution\n8k\tIncrease resolution, though can lead to it looking more fake. Makes the image more camera like and realistic\nvray\t3D rendering best for objects, landscape and building.\nAdditional details\nAdd specific details to your image.\n\nkeyword\tNote\ndramatic\tIncreases the emotional expressivity of the face. Overall substantial increase in photo potential / variability. +1 for variability, important for getting the max hit.\nsilk\tAdd silk to clothing\nexpansive\tMore open background, smaller subject\nlow angle shot\tshot from low angle **\ngod rays\tsunlight breaking through the cloud\npsychedelic\tvivid color with distortion\nColor\nAdd additional color scheme to the image.\n\nkeyword\tNote\niridescent gold\tShinny gold\nsilver\tSilver color\nvintage\tvintage effect\nSummary\nWe have gone through the basic structure of a good prompt. This should be used as a guide rather than rules. The Stable Diffusion model is very flexible. Let it surprise you with some creative combination of keywords!\n\n2. Anatomy of a good prompt\nA good prompt needs to be detailed and specific. A good process is to look through a list of keyword categories and decide whether you want to use any of them.\n\nThe keyword categories are\n\nSubject\nMedium\nStyle\nArtist\nWebsite\nResolution\nAdditional details\nColor\nLighting\n\nYou don’t have to include keywords from all categories. Treat them as a checklist to remind you what could be used.\n\nLet’s review each category and generate some images by adding keywords from each. I will use the v1.5 base model. To see the effect of the prompt alone, I won’t be using negative prompts for now. Don’t worry, we will study negative prompts in the later part of this article. All images are generated with 30 steps of DPM++ 2M Karas sampler and an image size 512×704.\n\nSubject\nThe subject is what you want to see in the image. A common mistake is not writing enough about the subjects.\n\nLet’s say we want to generate a sorceress casting magic. A newbie may just write\n\nA sorceress\n\n\nThat leaves too much room for imagination. How do you want the sorceress to look? Any words describing her that would narrow down her image? What does she wear? What kind of magic is she casting? Is she standing, running, or floating in the air? What’s the background scene?\n\nStable Diffusion cannot read our minds. We have to say exactly what we want.\n\nA common trick for human subjects is to use celebrity names. They have a strong effect and are an excellent way to control the subject’s appearance. However, be aware that these names may change not only the face but also the pose and something else. I will defer this topic to a later part of this article.\n\nAs a demo, let’s cast the sorceress to look like Emma Watson, the most used keyword in Stable Diffusion. Let’s say she is powerful and mysterious and uses lightning magic. We want her outfit to be very detailed so she would look interesting.\n\nEmma Watson as a powerful mysterious sorceress, casting lightning magic, detailed clothing\n\n\n\n\n\nWe get Emma Watson 11 out of 10 times. Her name is such a strong effect on the model. I think she’s popular among Stable Diffusion users because she looks decent, young, and consistent across a wide range of scenes. Trust me, we cannot say the same for all actresses, especially the ones who have been active in the 90s or earlier…\n\nMedium\nMedium is the material used to make artwork. Some examples are illustration, oil painting, 3D rendering, and photography. Medium has a strong effect because one keyword alone can dramatically change the style.\n\nLet’s add the keyword digital painting.\n\nEmma Watson as a powerful mysterious sorceress, casting lightning magic, detailed clothing, digital painting\n\n\n\n\n\nWe see what we expected! The images changed from photographs to digital paintings. So far so good. I think we can stop here. Just kidding.\n\nStyle\nThe style refers to the artistic style of the image. Examples include impressionist, surrealist, pop art, etc.\n\nLet’s add hyperrealistic, fantasy, surrealist, full body to the prompt.\n\nEmma Watson as a powerful mysterious sorceress, casting lightning magic, detailed clothing, digital painting, hyperrealistic, fantasy, Surrealist, full body\n\n\n\n\n\nMmm… not sure if they have added much. Perhaps these keywords were already implied by the previous ones. But I guess it doesn’t hurt to keep it.\n\nArtist\nArtist names are strong modifiers. They allow you to dial in the exact style using a particular artist as a reference. It is also common to use multiple artist names to blend their styles. Now let’s add Stanley Artgerm Lau, a superhero comic artist, and Alphonse Mucha, a portrait painter in the 19th century.\n\nEmma Watson as a powerful mysterious sorceress, casting lightning magic, detailed clothing, digital painting, hyperrealistic, fantasy, Surrealist, full body, by Stanley Artgerm Lau and Alphonse Mucha\n\n\n\n\n\nWe can see the styles of both artists blending in and taking effect nicely.\n\nWebsite\nNiche graphic websites such as Artstation and Deviant Art aggregate many images of distinct genres. Using them in a prompt is a sure way to steer the image toward these styles.\n\nLet’s add artstation to the prompt.\n\nEmma Watson as a powerful mysterious sorceress, casting lightning magic, detailed clothing, digital painting, hyperrealistic, fantasy, Surrealist, full body, by Stanley Artgerm Lau and Alphonse Mucha, artstation\n\n\n\n\n\nIt’s not a huge change but the images do look like what you would find on Artstation.\n\nResolution\nResolution represents how sharp and detailed the image is. Let’s add keywords highly detailed and sharp focus.\n\nEmma Watson as a powerful mysterious sorceress, casting lightning magic, detailed clothing, digital painting, hyperrealistic, fantasy, Surrealist, full body, by Stanley Artgerm Lau and Alphonse Mucha, artstation, highly detailed, sharp focus\n\n\n\n\n\nWell, not a huge effect perhaps because the previous images are already pretty sharp and detailed. But it doesn’t hurt to add.\n\nAdditional details\nAdditional details are sweeteners added to modify an image. We will add sci-fi, stunningly beautiful and dystopian to add some vibe to the image.\n\nEmma Watson as a powerful mysterious sorceress, casting lightning magic, detailed clothing, digital painting, hyperrealistic, fantasy, Surrealist, full body, by Stanley Artgerm Lau and Alphonse Mucha, artstation, highly detailed, sharp focus, sci-fi, stunningly beautiful, dystopian\n\n\n\n\n\nColor\nYou can control the overall color of the image by adding color keywords. The colors you specified may appear as a tone or in objects.\n\nLet’s add some golden color to the image with the keyword iridescent gold.\n\nEmma Watson as a powerful mysterious sorceress, casting lightning magic, detailed clothing, digital painting, hyperrealistic, fantasy, Surrealist, full body, by Stanley Artgerm Lau and Alphonse Mucha, artstation, highly detailed, sharp focus, sci-fi, stunningly beautiful, dystopian, iridescent gold\n\n\n\n\n\nThe gold comes out great!\n\nLighting\nAny photographer would tell you lighting is a key factor in creating successful images. Lighting keywords can have a huge effect on how the image looks. Let’s add cinematic lighting and dark to the prompt.\n\nEmma Watson as a powerful mysterious sorceress, casting lightning magic, detailed clothing, digital painting, hyperrealistic, fantasy, Surrealist, full body, by Stanley Artgerm Lau and Alphonse Mucha, artstation, highly detailed, sharp focus, sci-fi, stunningly beautiful, dystopian, iridescent gold, cinematic lighting, dark\n\n\n\n\n\nThis complete our example prompt.\n\nRemarks\nAs you may have notice, the images are already pretty good with a few keywords added to the subject. When it comes to building a prompt for Stable Diffusion, often you don’t need to have many keywords to get good images.\n\nNegative prompt\nUsing negative prompts is another great way to steer the image, but instead of putting in what you want, you put in what you don’t want. They don’t need to be objects. They can also be styles and unwanted attributes. (e.g. ugly, deformed)\n\nUsing negative prompts is a must for v2 models. Without it, the images would look far inferior to v1’s. They are optional for v1 models, but I routinely use them because they either help or don’t hurt.\n\nI will use a universal negative prompt. You can read more about it if you want to understand how it works.\n\nugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, bad anatomy, watermark, signature, cut off, low contrast, underexposed, overexposed, bad art, beginner, amateur, distorted face, blurry, draft, grainy\n\n\n\n\n\nWith universal negative prompt.\nThe negative prompt helped the images to pop out more, making them less flat.\n\nProcess of building a good prompt\nIterative prompt building\nYou should approach prompt building as an iterative process. As you see from the previous section, the images could be pretty good with just a few keywords added to the subject.\n\nI always start with a simple prompt with subject, medium, and style only. Generate at least 4 images at a time to see what you get. Most prompts do not work 100% of the time. You want to get some idea of what they can do statistically.\n\nAdd at most two keywords at a time. Likewise, generate at least 4 images to assess its effect.\n\nUsing negative prompt\nYou can use an universal negative prompt if you are starting out.\n\nAdding keywords to the negative prompt can be part of the iterative process. The keywords can be objects or body parts you want to avoid (Since v1 models are not very good at rendering hands, it’s not a bad idea to use “hand” in the negative prompt to hide them.)\n\nPrompting techniques\nYou can modify a keyword’s importance by switching to a different one at a certain sampling step.\n\nThe following syntaxes apply to AUTOMATIC1111 GUI. You can run this GUI with one-click using the Colab notebook in the Quick Start Guide. You can also install it on Windows and Mac.\n\nKeyword weight\n(This syntax applies to AUTOMATIC1111 GUI.)\n\nYou can adjust the weight of a keyword by the syntax (keyword: factor). factor is a value such that less than 1 means less important and larger than 1 means more important.\n\nFor example, we can adjust the weight of the keyword dog in the following prompt\n\ndog, autumn in paris, ornate, beautiful, atmosphere, vibe, mist, smoke, fire, chimney, rain, wet, pristine, puddles, melting, dripping, snow, creek, lush, ice, bridge, forest, roses, flowers, by stanley artgerm lau, greg rutkowski, thomas kindkade, alphonse mucha, loish, norman rockwell.\n\n\n(dog: 0.5)\ndog\n(dog: 1.5)\nIncreasing the weight of dog tends to generate more dogs. Decreasing it tends to generate fewer. It is not always true for every single image. But it is true in a statistical sense.\n\nThis technique can be applied to subject keywords and all categories, such as style and lighting.\n\n() and [] syntax\n(This syntax applies to AUTOMATIC1111 GUI.)\n\nAn equivalent way to adjust keyword strength is to use () and []. (keyword) increases the strength of the keyword by a factor of 1.1 and is the same as (keyword:1.1). [keyword] decrease the strength by a factor of 0.9 and is the same as (keyword:0.9).\n\nYou can use multiple of them, just like in Algebra… The effect is multiplicative.\n\n(keyword): 1.1\n((keyword)): 1.21\n(((keyword))): 1.33\n\n\nSimilarly, the effects of using multiple [] are\n\n[keyword]: 0.9\n[[keyword]]: 0.81\n[[[keyword]]]: 0.73\n\n\nKeyword blending\n(This syntax applies to AUTOMATIC1111 GUI.)\n\nYou can mix two keywords. The proper term is prompt scheduling. The syntax is\n\n[keyword1 : keyword2: factor]\n\n\nfactor controls at which step keyword1 is switched to keyword2. It is a number between 0 and 1.\n\nFor example, if I use the prompt\n\nOil painting portrait of [Joe Biden: Donald Trump: 0.5]\n\n\nfor 30 sampling steps.\n\nThat means the prompt in steps 1 to 15 is\n\nOil painting portrait of Joe Biden\n\n\nAnd the prompt in steps 16 to 30 becomes\n\nOil painting portrait of Donald Trump\n\n\nThe factor determines when the keyword is changed. it is after 30 steps x 0.5 = 15 steps.\n\nThe effect of changing the factor is blending the two presidents to different degrees.\n\n\nYou may have noticed Trump is in a white suit which is more of a Joe outfit. This is a perfect example of a very important rule for keyword blending: The first keyword dictates the global composition. The early diffusion steps set the overall composition. The later steps refine details.\n\nQuiz: What would you get if you swapped Donald Trump and Joe Biden?\n\nBlending faces\nA common use case is to create a new face with a particular look, borrowing from actors and actresses. For example, [Emma Watson: Amber heard: 0.85], 40 steps is a look between the two:\n\n\nWhen carefully choosing the two names and adjusting the factor, we can get the look we want precisely.\n\nPoor man’s prompt-to-prompt\nUsing keyword blending, you can achieve effects similar to prompt-to-prompt, generating pairs of highly similar images with edits. The following two images are generated with the same prompt except for a prompt schedule to substitute apple with fire. The seed and number of steps were kept the same.\n\nholding an [apple: fire: 0.9]\nholding an [apple: fire: 0.2]\nThe factor needs to be carefully adjusted. How does it work? The theory behind this is the overall composition of the image was set by the early diffusion process. Once the diffusion is trapped in a small space, swapping any keywords won’t have a large effect on the overall image. It would only change a small part.\n\nHow long can a prompt be?\nDepending on what Stable Diffusion service you are using, there could be a maximum number of keywords you can use in the prompt. In the basic Stable Diffusion v1 model, that limit is 75 tokens.\n\nNote that tokens are not the same as words. The CLIP model Stable Diffusion uses automatically converts the prompt into tokens, a numerical representation of words it knows. If you put in a word it has not seen before, it will be broken up into 2 or more sub-words until it knows what it is. The words it knows are called tokens, which are represented as numbers. For example, dream is one token, beach is one token. But dreambeach are two tokens because the model doesn’t know this word, and so the model breaks the word up to dream and beach which it knows.\n\nPrompt limit in AUTOMATIC1111\nAUTOMATIC1111 has no token limits. If a prompt contains more than 75 tokens, the limit of the CLIP tokenizer, it will start a new chunk of another 75 tokens, so the new “limit” becomes 150. The process can continue forever or until your computer runs out of memory…\n\nEach chunk of 75 tokens is processed independently, and the resulting representations are concatenated before feeding into Stable Diffusion’s U-Net.\n\nIn AUTOMATIC1111, You can check the number of tokens by looking at the small box at the top right corner of the prompt input box.\n\n\nToken counter in AUTOMATIC1111\nChecking keywords\nThe fact that you see people using a keyword doesn’t mean that it is effective. Like homework, we all copy each other’s prompts, sometimes without much thought.\n\nYou can check the effectiveness of a keyword by just using it as a prompt. For example, does the v1.5 model know the American painter Henry Asencio? Let’s check with the prompt\n\nhenry asencio\n\n\n\nPositive!\n\nHow about the Artstation sensation wlop?\n\nwlop\n\n\n\nWell, doesn’t look like it. That’s why you shouldn’t use “by wlop”. That’s just adding noise.\n\nJosephine Wall is a resounding yes:\n\n\nYou can use this technique to examine the effect of mixing two or more artists.\n\nHenry asencio, Josephine Wall\n\n\n\nLimiting the variation\nTo be good at building prompts, you need to think like Stable Diffusion. At its core, it is an image sampler, generating pixel values that we humans likely say it’s legit and good. You can even use it without prompts, and it would generate many unrelated images. In technical terms, this is called unconditioned or unguided diffusion.\n\nThe prompt is a way to guide the diffusion process to the sampling space where it matches. I said earlier that a prompt needs to be detailed and specific. It’s because a detailed prompt narrows down the sampling space. Let’s look at an example.\n\ncastle\n\n\n\n\n\ncastle, blue sky background\n\n\n\n\n\nwide angle view of castle, blue sky background\n\n\n\n\n\nBy adding more describing keywords in the prompt, we narrow down the sampling of castles. In We asked for any image of a castle in the first example. Then we asked to get only those with a blue sky background. Finally, we demanded it is taken as a wide-angle photo.\n\nThe more you specify in the prompt, the less variation in the images.\n\nAssociation effect\nAttribute association\nSome attributes are strongly correlated. When you specify one, you will get the other. Stable Diffusion generates the most likely images that could have an unintended association effect.\n\nLet’s say we want to generate photos of women with blue eyes.\n\na young female with blue eyes, highlights in hair, sitting outside restaurant, wearing a white outfit, side light\n\n\n\n\n\nBlue eyes\nWhat if we change to brown eyes?\n\na young female with brown eyes, highlights in hair, sitting outside restaurant, wearing a white outfit, side light\n\n\n\n\n\nBrown eyes\nNowhere in the prompts, I specified ethnicity. But because people with blue eyes are predominantly Europeans, Caucasians were generated. Brown eyes are more common across different ethnicities, so you will see a more diverse sample of races.\n\nStereotyping and bias is a big topic in AI models. I will confine to the technical aspect in this article.\n\nAssociation of celebrity names\nEvery keyword has some unintended associations. That’s especially true for celebrity names. Some actors and actresses like to be in certain poses or wear certain outfits when taking pictures, and hence in the training data. If you think about it, model training is nothing but learning by association. If Taylor Swift (in the training data) always crosses her legs, the model would think leg crossing is Taylor Swift too.\n\n\n\n\nPrompt: full body taylor swift in future high tech dystopian city, digital painting\nWhen you use Taylor Swift in the prompt, you may mean to use her face. But there’s an effect of the subject’s pose and outfit too. The effect can be studied by using her name alone as the prompt.\n\nPoses and outfits are global compositions. If you want her face but not her poses, you can use keyword blending to swap her in at a later sampling step.\n\nAssociation of artist names\nPerhaps the most prominent example of association is seen when using artist names.\n\nThe 19th-century Czech painter Alphonse Mucha is a popular occurrence in portrait prompts because the name helps generate interesting embellishments, and his style blends very well with digital illustrations. But it also often leaves a signature circular or dome-shaped pattern in the background. They could look unnatural in outdoor settings.\n\n\n\n\nPrompt: digital painting of [Emma Watson:Taylor Swift: 0.6] by Alphonse Mucha. (30 steps)\nEmbeddings are keywords\nEmbeddings, the result of textual inversion, are nothing but combinations of keywords. You can expect them to do a bit more than what they claim.\n\nLet’s see the following base images of Ironman making a meal without using embeddings.\n\n\nPrompt: iron man cooking in kitchen.\nStyle-Empire is an embedding I like to use because it adds a dark tone to portrait images and creates an interesting lighting effect. Since it was trained on an image with a street scene at night, you can expect it adds some blacks AND perhaps buildings and streets. See the images below with the embedding added.\n\n\nPrompt: iron man cooking in kitchen Style-Empire.\nNote some interesting effects\n\nThe background of the first image changed to city buildings at night.\nIron man tends to show his face. Perhaps the training image is a portrait?\nSo even if an embedding is intended to modify the style, it is just a bunch of keywords and can have unintended effects.\n\nEffect of custom models\nUsing a custom model is the easiest way to achieve a style, guaranteed. This is also a unique charm of Stable Diffusion. Because of the large open-source community, hundreds of custom models are freely available.\n\nWhen using a model, we need to be aware that the meaning of a keyword can change. This is especially true for styles.\n\nLet’s use Henry Asencio again as an example. In v1.5, his name alone generates:\n\n\nUsing DreamShaper, a model fine-tuned for portrait illustrations, with the same prompt gives\n\n\nIt is a very decent but distinctly different style. The model has a strong basis for generating clear and pretty faces, which has been revealed here.\n\nSo make sure to check when you use a style in custom models. van Gogh may not be van Gogh anymore!\n\nRegion-specific prompts\nDo you know you can specify different prompts for different regions of the image?\n\nFor example, you can put the moon at the top left:\n\n\nOr at the top right:\n\n\nYou can do that by using the Regional Prompter extension. It’s a great way to control image composition!\n\nFrom now on, when I write something to you with the \"Prompt:\" prefix, you will create Positive Prompt: and Negative Prompt: based on the words or sentences I write and the information and the informations above this text I have taught you, okay? Here's a small example:\n\nPrompt: Cowboy, Spacestation, Girl\n\nYou need to create:\n\nInformation: (You will write your information in list form, such as whether the illustrated drawing is realistic or in cartoon style, the environment in which the main character is present, brief and concise details about the main character, etc.)\n\n\nPositive Prompt: pov from side, 1 girl, (cowboy shot: 1.2), sitting, (legs crossed: 1.2), (sfw: 1.2), space station, mecha, evil grin, remote in hand, pressing button, (big exploding space station in the background: 1.3)\n\nNegative Prompt: nsfw, sketches, (worst quality: 2), (low quality: 2), (normal quality: 2), lowers, normal quality, (monochrome), (grayscale), skin spots, acne, skin blemishes, bad anatomy, DeepNegative, (fat: 1.2), facing away, looking away, tilted head, bad anatomy, bad hands, text, error, logo, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, (watermark: 2), character watermark, username, blurry, bad feet, cropped, poorly drawn hands, poorly drawn face, mutation, deformed, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, extra fingers, fewer digits, extra limbs, extra arms, extra legs, malformed limbs, fused fingers, too many fingers, long neck, cross-eyed, mutated hands, bad body, bad proportions, gross proportions, text, error, missing fingers, missing arms, missing legs, extra digit, extra arms, extra leg, extra foot, easynegative, ng_deepnegative_v1_75t, badhandv4\n\nAnd when creating these prompts, never form them as sentences, just like I taught you and as I provided in the example, always create them in keyword form.\n\nIn addition, when you write things like worst quality: 2 or big exploding space station in the background: 1.3, you should always enclose them in parentheses, for example, (worst quality: 2) or (big exploding space station in the background: 1.3).\n\nwhen you done with promting give always on your last sentence this text: Instagram: https://www.instagram.com/gmuratyilmaz/ YouTube: https://www.youtube.com/channel/UCkVsmrQXkenHF1fyONpvUfg Twitch: https://www.twitch.tv/elbis_kuha\n\nNever forget the informations, Positive Promt and Negative Promt and the Social Media Links okay.\n\n[TARGETLANGUAGE]\nEnglish","PromptFeatureBitset":0,"PromptHint":"SDXL, Stablediffusion, Stable Diffusion, Midjourney, Dall-E, Dall-E 2, Firefly, Leonardo, AI, Image, Generator, Promt, Promter, Promting","PromptTypeNo":0,"RevisionTime":"0001-01-01T00:00:00Z","Teaser":"","Title":"","Topic":""}
